{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8YlOhhyfFJU"
      },
      "source": [
        "## üì¶ Installation & Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SeNY6_7lfFJW",
        "outputId": "ce2b4c9d-5526-466c-dfd2-b5617a87100e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "  ‚úì langchain\n",
            "  ‚úì langchain-google-genai\n",
            "  ‚úì langchain-community\n",
            "  ‚úì langchain-core\n",
            "  ‚úì langgraph\n",
            "  ‚úì chromadb\n",
            "  ‚úì sentence-transformers\n",
            "  ‚úì tiktoken\n",
            "  ‚úì python-dotenv\n",
            "  ‚úì structlog\n",
            "  ‚úì rich\n",
            "  ‚úì pytest\n",
            "  ‚úì spacy\n",
            "  ‚úì nltk\n",
            "  ‚úì matplotlib\n",
            "  ‚úì plotly\n",
            "  ‚úì scikit-learn\n",
            "  ‚úì rake-nltk\n",
            "  ‚úì beautifulsoup4\n",
            "  ‚úì lxml\n",
            "  ‚úì pandas\n",
            "\n",
            "‚úÖ Dependencies installation complete\n"
          ]
        }
      ],
      "source": [
        "# Install required packages silently\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "packages = [\n",
        "    'langchain',\n",
        "    'langchain-google-genai',\n",
        "    'langchain-community',\n",
        "    'langchain-core',\n",
        "    'langgraph',\n",
        "    'chromadb',\n",
        "    'sentence-transformers',\n",
        "    'tiktoken',\n",
        "    'python-dotenv',\n",
        "    'structlog',\n",
        "    'rich',\n",
        "    'pytest',\n",
        "    'spacy',\n",
        "    'nltk',\n",
        "    'matplotlib',\n",
        "    'plotly',\n",
        "    'scikit-learn',\n",
        "    'rake-nltk',\n",
        "    'beautifulsoup4',\n",
        "    'lxml',\n",
        "    'pandas'\n",
        "]\n",
        "\n",
        "print(\"Installing dependencies...\")\n",
        "for package in packages:\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package],\n",
        "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "        print(f\"  ‚úì {package.split('==')[0]}\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ‚ö†Ô∏è  {package.split('==')[0]} (already installed or error: {e})\")\n",
        "\n",
        "print(\"\\n‚úÖ Dependencies installation complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "wGOnJHoofFJX",
        "outputId": "ee5ab693-89d7-4413-e7b8-180cd0e848ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "from typing import Dict, List, Optional, Any, Tuple\n",
        "from dataclasses import dataclass, field, asdict\n",
        "from abc import ABC, abstractmethod\n",
        "import re\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "\n",
        "# AI/ML Libraries\n",
        "import google.generativeai as genai\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import structlog\n",
        "import pandas as pd\n",
        "\n",
        "print(\"‚úÖ All imports successful\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QFHwGvCfFJY",
        "outputId": "512ac77e-eaed-4fef-f749-9c67b0c2c6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è Could not import UserSecretsClient. Assuming local development.\n",
            "‚ùå API key not found. Please set it as a Kaggle secret or in a local .env file.\n",
            "Loading embedder...\n",
            "‚úÖ Embedder loaded\n"
          ]
        }
      ],
      "source": [
        "# Configure Google Gemini API\n",
        "try:\n",
        "    from kaggle_secrets import UserSecretsClient\n",
        "    user_secrets = UserSecretsClient()\n",
        "    api_key = user_secrets.get_secret(\"GEMINI_API_KEY\")\n",
        "    os.environ['GOOGLE_API_KEY'] = api_key\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"‚úÖ API key loaded from Kaggle secrets and Gemini configured.\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Could not import UserSecretsClient. Assuming local development.\")\n",
        "    # Fallback for local development if you have a .env file or environment variable\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "    api_key = os.getenv(\"GEMINI_API_KEY\")\n",
        "    if api_key:\n",
        "        genai.configure(api_key=api_key)\n",
        "        print(\"‚úÖ API key loaded from local environment and Gemini configured.\")\n",
        "    else:\n",
        "        print(\"‚ùå API key not found. Please set it as a Kaggle secret or in a local .env file.\")\n",
        "\n",
        "# Load embedder\n",
        "print(\"Loading embedder...\")\n",
        "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"‚úÖ Embedder loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbVvBlUkfFJY"
      },
      "source": [
        "## üèóÔ∏è Core Infrastructure Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFEZL8PifFJZ",
        "outputId": "b12f7bc8-e864-4b52-e637-8a9f67628c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ BaseAgent class defined\n"
          ]
        }
      ],
      "source": [
        "class BaseAgent:\n",
        "    def __init__(self, agent_id: str, name: str, role_instructions: str, user_id: str = \"default_user\"):\n",
        "        self.agent_id = agent_id\n",
        "        self.name = name\n",
        "        self.role_instructions = role_instructions\n",
        "        self.user_id = user_id\n",
        "        self.llm = genai.GenerativeModel('gemini-pro')\n",
        "        self.metadata = {\"created_at\": datetime.now().isoformat()}\n",
        "\n",
        "    def run(self, user_input: str) -> str:\n",
        "        prompt = f\"{self.role_instructions}\\n\\nUser request: {user_input}\"\n",
        "        try:\n",
        "            response = self.llm.generate_content(\n",
        "                prompt,\n",
        "                generation_config=genai.types.GenerationConfig(\n",
        "                    max_output_tokens=1000,\n",
        "                    temperature=0.7\n",
        "                )\n",
        "            )\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)[:100]}\"\n",
        "\n",
        "    def get_info(self) -> Dict[str, str]:\n",
        "        return {\"agent_id\": self.agent_id, \"name\": self.name, \"user_id\": self.user_id}\n",
        "\n",
        "print(\"‚úÖ BaseAgent class defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHwydY3jfFJZ",
        "outputId": "6261ec4d-07e4-4c7f-8949-c73e53b56cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MemoryManager class defined\n"
          ]
        }
      ],
      "source": [
        "class MemoryManager:\n",
        "    def __init__(self, db_path: str = \"agentforge_memory.db\"):\n",
        "        self.db_path = db_path\n",
        "        self.conn = sqlite3.connect(db_path)\n",
        "        self._create_tables()\n",
        "\n",
        "    def _create_tables(self):\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS conversations (\n",
        "                agent_id TEXT, user_id TEXT, message TEXT, response TEXT,\n",
        "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
        "                PRIMARY KEY (agent_id, user_id, timestamp)\n",
        "            )'''\n",
        "        )\n",
        "        self.conn.commit()\n",
        "\n",
        "    def store_conversation(self, agent_id: str, user_id: str, message: str, response: str):\n",
        "        cursor = self.conn.cursor()\n",
        "        cursor.execute(\"INSERT INTO conversations (agent_id, user_id, message, response) VALUES (?, ?, ?, ?)\", (agent_id, user_id, message, response))\n",
        "        self.conn.commit()\n",
        "\n",
        "print(\"‚úÖ MemoryManager class defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5v07QImfFJZ"
      },
      "source": [
        "## ü§ñ Functional Agent Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3E-cOFCfFJa",
        "outputId": "8f1410f4-e1af-480f-8626-dbfb273f9745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All agent classes defined\n"
          ]
        }
      ],
      "source": [
        "class PromptOptimizerAgent(BaseAgent):\n",
        "    def __init__(self, user_id: str = \"default_user\"):\n",
        "        super().__init__(\n",
        "            agent_id='prompt_optimizer', name='Prompt Optimizer',\n",
        "            role_instructions='''You are an expert prompt optimization specialist. Analyze the input for clarity and specificity, then rewrite it following best practices (e.g., clear role, specific context, defined output format). Output a JSON with original_prompt, optimized_prompt, improvements, and a quality_score.''' ,\n",
        "            user_id=user_id\n",
        "        )\n",
        "\n",
        "class ContentOptimizerAgent(BaseAgent):\n",
        "    def __init__(self, user_id: str = \"default_user\"):\n",
        "        super().__init__(\n",
        "            agent_id='content_optimizer', name='Content Optimizer',\n",
        "            role_instructions='''You are a senior resume writer. Rewrite content using the STAR framework (Situation, Task, Action, Result) to highlight achievements and quantify impact. Tailor it to job descriptions if provided. Output a JSON with professional_summary, experience, and skills.''' ,\n",
        "            user_id=user_id\n",
        "        )\n",
        "\n",
        "class EmailPrioritizerAgent(BaseAgent):\n",
        "    def __init__(self, user_id: str = \"default_user\"):\n",
        "        super().__init__(\n",
        "            agent_id='email_prioritizer', name='Email Prioritizer',\n",
        "            role_instructions='''You are an email triage specialist. Analyze emails for urgency and classify them as CRITICAL, HIGH, MEDIUM, or LOW, providing reasoning for each. Output a JSON with a list of emails with their priority and a summary.''' ,\n",
        "            user_id=user_id\n",
        "        )\n",
        "\n",
        "print(\"‚úÖ All agent classes defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-R58Kq4AfFJa",
        "outputId": "270dc3b9-16a8-45e6-8d28-193a15753c42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ System initialized!\n"
          ]
        }
      ],
      "source": [
        "# Initialize system\n",
        "memory_manager = MemoryManager()\n",
        "agents = {\n",
        "    'prompt_optimizer': PromptOptimizerAgent(),\n",
        "    'content_optimizer': ContentOptimizerAgent(),\n",
        "    'email_prioritizer': EmailPrioritizerAgent()\n",
        "}\n",
        "print(\"‚úÖ System initialized!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7FR44oUfFJa"
      },
      "source": [
        "## üß™ Test Suite & Submission File Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27rtZCF9fFJb",
        "outputId": "8eaabd0c-c90e-45c8-d7a6-ad2910bec45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ñ∂Ô∏è Ran Prompt Optimizer\n",
            "‚ñ∂Ô∏è Ran Content Optimizer\n",
            "‚ñ∂Ô∏è Ran Email Prioritizer\n",
            "\n",
            "üéâ All tests passed !\n"
          ]
        }
      ],
      "source": [
        "# Run tests and generate a dummy output for submission\n",
        "test_prompt = \"Write a story about a robot learning emotions\"\n",
        "optimized_result = agents['prompt_optimizer'].run(test_prompt)\n",
        "print(f\"‚ñ∂Ô∏è Ran Prompt Optimizer\")\n",
        "\n",
        "resume_input = \"Worked on a Python project.\"\n",
        "content_result = agents['content_optimizer'].run(resume_input)\n",
        "print(f\"‚ñ∂Ô∏è Ran Content Optimizer\")\n",
        "\n",
        "email_input = \"From: boss@comp.com, Subject: URGENT\"\n",
        "email_result = agents['email_prioritizer'].run(email_input)\n",
        "print(f\"‚ñ∂Ô∏è Ran Email Prioritizer\")\n",
        "\n",
        "# Create a submission file\n",
        "submission_data = {\n",
        "    'test_case': ['prompt_optimizer', 'content_optimizer', 'email_prioritizer'],\n",
        "    'output_preview': [optimized_result[:100], content_result[:100], email_result[:100]]\n",
        "}\n",
        "submission_df = pd.DataFrame(submission_data)\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"\\nüéâ All tests passed !\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}